# 云计算认证笔记

## 云计算简介

- 云计算是什么
- 云计算历史
- 云计算案例
- 云计算特点

![092643c6l4nbneayy4ot1d](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/092643c6l4nbneayy4ot1d.png?raw=true)



### 优势

1. 按需自助服务
2. 广泛的网络接入
3. 资源池化
4. 快速弹性伸缩
5. 可计量服务

### 定义

​	云计算是一种**模型**，可以实现随时随地，便捷地，随需应变地从可配置计算资源共享池中获取所需的**资源(网络，服务器，存储，应用及服务)**，资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减少到最低限度。

​	通俗讲，云，是网络，互联网的一种比喻说法，即互联网与建立互联网所需要的底层基础设施的抽象体。计算指的是一台足够强大的计算机提供的计算服务，包括各种功能，资源，存储。云计算可以理解：通过互联网可以使用足够的计算机为用户提供的服务，这种服务的使用量可以使用统一的单位来描述。

### 互联网发展史

ARPANET - > TCP/IP - > DNS -> www - > Facebook社交网络元年 - > HTTPS

![1576739001(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576739001(1).jpg?raw=true)

### 计算发展史

1. 串行式计算：如果问题太复杂，处理时间会较长。如果解决更大规模的问题，用单个CPU解决不切实际。

   限制：

   - 传输速度，线性计算机的执行速度直接取决于数据在硬件中传输的速度
   - 微型化极限，处理器技术使芯片集成了更多的晶体管。但是芯片集成晶体管有极限
   - 经济上的限制，让单个芯片变得更快需要增加昂贵的投入

2. 并行式计算：让多个CPU同时参与到任务的执行中。

   特点：

   - 节省时间和成本
   - 解决使用串行计算无法解决的问题

3. 分布式计算：将自己所有组件分散在属于不同网络的计算机上，通过统一的消息机制来相互通讯和配合，完成共同的目标。

   优点：

   - 稀有资源可以共享
   - 通过分布式计算可以在多台计算机上平衡计算负载
   - 可以把程序放在最适合它的计算机上

   其中共享稀有资源和平衡负载是核心思想之一

4. 网格计算：利用广泛的零散的计算资源完成一个共同任务，也是分布式计算的一种。通常使用集群的方式实现。

5. 云计算：共享基础架构的方法，可以将巨大的系统池连接在一起以提供各种IT服务。

   - 狭义云计算：IT基础设施的交付和使用模式，通过网络以按需，易扩展的方式获取所需的资源(硬件、平台、软件)。可以随时获取，按需使用，随时扩展，按使用付费。
   - 广义云计算：服务的交付和使用模式，通过网络以按需、易扩展的方式获得所需的服务。这种服务可以是IT、软件和互联网相关的，也可以是其他任意的服务。

   云计算相同点：

   1. 超大规模
   2. 虚拟化
   3. 高可靠性
   4. 通用性
   5. 高扩展性
   6. 按需服务
   7. 极其廉价

![1576739106(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576739106(1).jpg?raw=true)

### 云计算发展

1. 云计算 1.0

   面向数据中心管理员的IT基础设施资源虚拟化阶段。关键特征是通过计算虚拟化技术的引入，将企业IT应用与底层的基础设施彻底分离解耦，将多个企业IT应用实例及运行环境复用在相同的物理服务器上，并通过虚拟化集群调度软降，将更多的IT应用复用在更少的服务器节点上，从而实现资源利用率的提升。

2. 云计算 2.0

   面向基础设施云租户和云用户的资源服务化与管理自动化阶段。特征为通过平面的基础设计标准化服务于资源调度自动化软件的引入，以及数据平面的软件定义存储和软件网络技术，面向内部和外部的租户，将原本需要通过数据中心管理员人工干预的基础设施资源复杂低效申请、释放和配置过程，转变为在必要的限定条件下的一键式全自动化资源发放服务过程。

   基础设施资源服务供给，可以是虚拟机形式，可以是容器形式，也可以是物理机形式。

3. 云计算 3.0

   面向企业IT应用开发者及管理维护者的企业应用架构的分布式微服务化和企业数据架构的互联网重构及大数据智能化阶段。将走向(依托开源增强的、跨不同业务应用领域高度共享的)数据库，中间件平台服务层及(功能更加轻量化解耦、数据和应用逻辑彻底分离的)分布式无状态化架构。

![1576739142(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576739142(1).jpg?raw=true)

### 云计算模式

运营模式

- 公有云：百度云，华为云，有道云
- 私有云：部署在企业和单位内部，私有云上的数据全部保存在企业自有的数据中心。或在公有云上购买专属云服务，将关键业务放在公有云上，保证用户在云上拥有专属的计算和存储资源。
- 混合云：由于安全和控制原因，并非所有企业信息都能放在公有云上，这样将会使用混合云模式，同时使用公有云和私有云。
- 行业云：以公开或半公开的方式，向行业内部或相关组织和公众提供有偿或无偿服务的云平台，具有一些行业特性。如医药行业，银行业等。

服务模式

- IaaS：基础设施层由云服务商提供，其他由用户自营
- PaaS：基础设施层和平台层由云服务商提供，其他由用户自营
- SaaS：全部由云服务商提供

![1576739467(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576739467(1).jpg?raw=true)

## 实验手册

![152006hoodzc7yeinyiiib](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/152006hoodzc7yeinyiiib.png?raw=true)

## 计算虚拟化

使用虚拟化，可以在物理服务器上模拟出多个独立的服务器来。本质是将原先的物理设备进行逻辑化，转化成一个文件夹或文件，实现软硬件的解耦。

### 计算虚拟化发展史

1. IBM实现分时系统，并将一个CPU虚拟化成多个虚拟CPU，并且让每颗CPU看起来在同时运行，推出system370机。
2. VMware推出最早的能在X86架构上运行的虚拟化产品。
3. Xen正式被开源，开始支持Intel，可以运行完全没有修改的操作系统。
4. Qumranet正式对外宣布KVM诞生，KVM模块的源代码正式被纳入Linux Kernel。
5. Linux推出LXC，是第一套完整的Linux容器管理实现方案。
6. Docker引入一整套和容器管理相关的生态系统。

![1576741245(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576741245(1).jpg?raw=true)

### 虚拟化架构

 ![1576741291(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576741291(1).jpg?raw=true)

- Guest OS：虚拟机操作系统
- Guest Machine：虚拟出来的虚拟机
- Hypervisor：虚拟化软件层/虚拟机监控机
- Host OS：运行在物理机上的OS
- Host Machine：物理机

### 虚拟化分类

根据Hypervisor的不同类型，我们将虚拟化分为 I 型和 II 型两种(把容器算成 III 型)。

- **I 型**：裸金属虚拟化，Hypervisor直接调用硬件资源，不需要底层Host OS。可以将Hypervisor看作成一个定制的Host OS，除了起到VMM的作用外，一般不能在其上安装其他应用。

  Hypervisor主要实现两个基本功能：

  1. 首先是识别、捕获和响应虚拟机发出的CPU特权指令或保护指令；
  2. 其次，它负责处理虚拟机队列和调度，并将物理硬件的处理结果返回给相应的虚拟机。也就是说，Hypervisor负责管理所有的资源和虚拟环境。

  **特点**

  ​	优点：虚拟机不依赖于操作系统，支持多种操作系统和多种应用。

  ​	缺点：虚拟化层内核开发难度大。

- **II 型：** 宿主型虚拟化，此模型的物理资源又Host OS(例如 Windows Linux)管理，实际的虚拟化功能由VMM提供。

  VMM：

  通过创建相应的虚拟机，共享底层服务器资源。通过调用Host OS的服务来获得资源，实现CPU、内核和I/O设备的虚拟化。

  **特点**

  ​	优点：简单、易于实现

  ​	缺点：安装和运行应用程序依赖于主机操作系统对设备的支持。管理开销较大，性能损耗大。

![1576742231(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576742231(1).jpg?raw=true)

### 虚拟化特点

- 分区：意味着虚拟化层为多个虚拟机划分服务器资源的能力。解决两方面问题：
  1. 每个分区划分资源配额，防止虚拟化超配额使用资源
  2. 每个虚拟机单独安装操作系统，彼此互不影响
- 隔离：通过分区所建立的多个虚拟机之间采用逻辑隔离措施，防止相互影响。解决两方面问题：
  1. 一个虚拟机的崩溃或故障，不会影响同一服务器上的其他虚拟机
  2. 一个虚拟机中的病毒，蠕虫等，与其他虚拟机相隔离，就像每个虚拟机都位于单独的物理机上一样
- 封装：将整个虚拟机(硬件配置、BIOS配置、内存状态、磁盘状态、CPU状态)储存在独立于物理硬件的一小组文件中。只需复制几个文件就可以随时随地根据需要复制、保存和移动虚拟机。对虚拟机的迁移而言，最重要的就是封装特性。
- 独立：虚拟机封装为独立文件后，虚拟机迁移只需要把虚拟机设备文件和配置文件或磁盘文件复制到另一台主机上运行即可，而不用关心底层的硬件类型是否兼容，这就是相对硬件的独立性。

### CPU虚拟化

CPU的分级保护域，在这种保护模式中，CPU被分为4个环

- Ring 0：最高权限，可以直接操作硬件，一般只有操作系统和驱动会允许拥有此权限。
- Ring 1：次之
- Ring 2：再次之
- Ring 3：最低权限，所有程序都拥有此权限。

主机操作系统所发出的指令一般分为两种：特权指令和普通指令

- 特权指令：用于操作和管理关键系统资源的指令，这些指令只在最高特权级上才能够运行，即必须在Ring 0级别上才能运行
- 普通指令：这些指令在CPU普通权限级别上就能够运行，即在Ring 3级别上可以运行。

**CPU虚拟化解决方案**

- 全虚拟化
- 半虚拟化
- 硬件辅助虚拟化

**全虚拟化**

​	经典“特权解除”和“陷入模式”虚拟化方案不适合X86架构的CPU，根本原因在那19条超出特权指令的敏感指令，运行在Ring 1用户态，不能陷入-模拟被虚拟机监控器(VMM)捕获。

​	虚拟机发出的操作系统请求转发到VMM，VMM对请求进行二进制翻译，如果发型特权指令或敏感指令，则陷入到VMM模式执行，然后调度到CPU特权级别上执行；如果只是应用程序指令则直接在CPU非特权级别上执行。这种方法需要过滤所有虚拟机发出的请求指令，因而被称为全虚拟化方式。

**半虚拟化**

​	虚拟化漏洞的问题来源于19条敏感指令，如果我们可以修改虚拟操作系统Guest OS规避虚拟化漏洞，那么问题就解决了。

​	半虚拟化修改虚拟机操作系统Guest OS，让虚拟机操作系统能够意识到自己是被虚拟化的，虚拟机操作系统会“超级调用”Hypervisor层来替换虚拟化中的敏感指令，从而实现虚拟化，而其他应用程序等非敏感或非特权请求则直接在CPU非特权级别上执行。

 ![1576742293](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576742293.jpg?raw=true)

**硬件辅助虚拟化**

​	虚拟化漏洞问题的解决，无论是全虚拟化还是半虚拟化，都默认物理硬件不具备虚拟化识别功能，因此必须识别这19条敏感指令，并通过VMM进行陷入-模拟。

​	Intel推出VT-x的CPU，AMD也推出AMD-V的CPU。VT-x和AMD-V，这两种技术都为CPU增加了新的执行模式 - root模式。可以让VMM运行在root模式下，而root模式位于CPU指令级别Ring 0下。

​	特权和敏感指令自动在Hypervisor上执行，所以无需全虚拟化或半虚拟化技术。这种通过硬件辅助虚拟化解决虚拟化漏洞，简化VMM工作。

![1577455116(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577455116(1).jpg?raw=true)

### 内存虚拟化

​	内存虚拟化把物理机的真实物理内存统一管理，包装成多份虚拟的内存给若干虚拟机使用。核心在于引入一层新的地址空间 - 客户机物理地址空间。客户机以为自己运行在真实的物理地址空间中，实际上它是通过VMM访问真实的物理地址，在VMM中保存的是客户机地址空间和物理机地址空间之间的映射表。

![1576742321(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576742321(1).jpg?raw=true)

​	内存虚拟化的内存地址涉及三种内存地址：虚拟机内存地址(VA)，物理内存地址(PA)和机器内存地址(MA)。

​	需要实现	VA(虚拟内存) - > PA(物理内存) - > MA(机器内存) 之间地址转换。虚拟机Guest OS控制虚拟地址到客户内存物理地址的映射( VA - > PA )，Hypervisor负责映射客户物理内存到实际机器内存( PA - > MA )。

### I/O虚拟化

​	VMM用于截获虚拟机对I/O设备的访问请求，再通过软件去模拟真实的I/O设备，进而响应I/O请求。

实现I/O虚拟化的方式主要有三种

- 全虚拟化
- 半虚拟化
- 硬件辅助虚拟化：是目前I/O虚拟化的主流技术

**全虚拟化**

​	通过VMM为虚拟机模拟出一个与真实设备类似的虚拟I/O设备，当虚拟机对I/O设备发起I/O请求时，VMM截获虚拟机下发的I/O访问请求，再由VMM将真实的访问请求发送到物理设备进行处理。

​	优点：无论使用任何类型操作系统，都不要为I/O虚拟化做任何修改，可以让多个虚拟机直接使用物理服务器的I/O设备

​	缺点：VMM需要实时截获每个虚拟机下发的I/O请求，然后模拟到真实的I/O设备中。给服务器带来较严重的性能损耗。

**半虚拟化**

​	需要建立一个特权级别的虚拟机。要求各个虚拟机运行前端驱动程序，当访问I/O设备时，虚拟机通过前端驱动程序把I/O请求发送给特权虚拟机，由特权虚拟机后端驱动收集每个虚拟机发出的I/O请求，再由后端驱动对多个I/O请求进行分时分通道处理。

​	特权虚拟机运行真实的物理I/O设备驱动，将I/O请求发送给物理I/O设备，I/O设备处理完成后再将结果返回给虚拟机。

​	优点：主动让虚拟机把I/O请求发送给特权虚拟机，再由特权虚拟机访问真实的I/O设备，减少VMM性能损耗

​	缺点：需要修改虚拟机操作系统，改变操作系统对自身I/O请求的处理方式。

 ![1577456745(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577456745(1).jpg?raw=true)

Domain 0就是特权虚拟机，Domain U是用户虚拟机。

**硬件辅助虚拟化**

​	将I/O设备驱动直接安装在虚拟机操作系统中，不需要对操作系统做任何修改。IO透传，直接分配给虚拟机物理设备，例如直接分配一个硬盘或网卡给虚拟机，需要硬件具备IO透传技术。

### Xen和KVM比较

**Xen**

​	同时支持半虚拟化和全虚拟化，直接运行在硬件上，然后在其之上运行虚拟机。Xen中的虚拟机分为两类：Domain 0和Domain U。Domain 0是一个特权虚拟机，具有直接访问硬件和管理其他普通虚拟机Domain U的权限。Domain 0先启动，Domain U后启动，然后将所有的操作都通过前后端驱动的方式转给Domain 0，再由Domain 0完成具体的操作后将结果返回给Domain U。

![1576742516(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576742516(1).jpg?raw=true)

**KVM**

​	KVM，全称是Kernel-base Virtual Machine(基于内核的虚拟机)，是一种典型的 II 型全虚拟化。KVM本身是一个Linux内核模块，当安装有Linux系统的物理机有这个模块后，就变成了Hypervisor，而且不会影响原先在该Linux上运行的其他应用程序，而且每个虚拟机都是进程，可以直接用Kill命令杀掉。

一个Linux安装KVM模块后，会增加三种运行模式

- Guest Mode：主要是指虚拟机，包括虚拟机的CPU、内存、磁盘等虚拟设备，该模式被置于一种受限的CPU模式下运行；
- User Mode：此模式下运行的主要是QEMU，用来为虚拟机模拟执行I/O类的操作请求；
- Kernel Mode：此模式下可以真正操作硬件，当Guest OS执行I/O类操作或特权指令操作时，需要向用户模式提交请求，然后由用户模式再次发起硬件操作请求给内核模式，从而真正操作硬件。

KVM体系包括三部分

- KVM内核模块
- QEMU
- 管理工具

 ![1577458543(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577458543(1).jpg?raw=true)

​	KVM内核模块中，实现虚拟化功能的是kvm.ko，还包括一个和处理器强相关的模块如kvm-intel.ko或kvm-amd.ko。KVM本身不能实现任何模拟功能，它仅仅是提供一个/dev/kvm接口，可被宿主机用来主要负责vCPU的创建、虚拟内存的地址空间分配、vCPU寄存器的读写以及vCPU的运行。

​	KVM核心模块和QEMU一起才能构建一个完整的虚拟化技术。Guest OS以为自己在与硬件进行交互，其实真正交互的是QEMU，然后通过QEMU与硬件交互。

​	在QEMU - KVM中，KVM运行在内核空间，QEMU运行在用户空间。Guest OS下发指令时，与CPU和内存相关的指令会通过QEMU - KVM中的 /ioctl 调用/dev/kvm，从而将这部分指令交给内核模块来完成。从QEMU角度看，可以加速虚拟化。其他 I/O操作则由 QEMU - KVM 中的QEMU来实现，KVM加上QEMU后才是完整意义上的虚拟化。

**Virtio**

没有Virtio时，虚拟机磁盘操作实现

 ![1577594824(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577594824(1).jpg?raw=true)

1. 虚拟机中的磁盘设备发起一次I/O操作请求；
2. KVM模块中的I/O Trap Code(I/O捕获程序)将这个I/O操作请求捕获，进行相应的处理，然后将处理后的请求放到I/O共享页中；
3. KVM模块会通知QEMU，有新的I/O操作请求放在共享页中；
4. QEMU收到通知后，到共享页中获取该I/O操作请求的具体信息；
5. QEMU对该请求进行模拟，同时根据I/O操作请求的信息调用运行在内核太的设备驱动，进行真正的I/O操作；
6. 通过设备驱动对物理硬件执行真正的I/O操作；
7. QEMU将执行后的结果返回给共享页中，同时通知KVM模块已完成此次I/O操作；
8. I/O捕获程序从共享页中读取返回的结果；
9. I/O捕获程序将操作结果返回给虚拟机；
10. 虚拟机将结果返回给发起操作的应用程序。

*注：2、3、7步，KVM除了捕获和通知，并没有对I/O操作做任何的修改*

使用Virtio时的具体操作流程

 ![1577595246(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577595246(1).jpg?raw=true)

1. 同样是由虚拟机发起I/O操作请求；
2. 与使用默认模型不一样，这个I/O操作请求不会经过I/O捕获程序，而是直接以前后端的形式放到环形缓冲区，同时KVM模块通知后端驱动；
3. QEMU到环形缓冲区获取到操作请求的具体信息；
4. 后端驱动直接调用真实的物理设备驱动进行具体I/O操作；
5. 由真实的设备驱动完成I/O操作；
6. QEMU将处理结果返回环形缓冲区，并由KVM模块通知前端驱动；
7. 前端驱动从环形缓冲区获取到此次I/O操作的结果；
8. 前端驱动将结果返回给发起操作的应用程序；

使用Virtio的优点：

- 节省QEMU模拟时所需的硬件资源
- 缩短I/O请求的路径，提高虚拟化设备的性能

### FusionCompute

FusionSphere虚拟化套件带来价值

- 帮助客户替身数据中心基础设施的资源利用率
- 帮助客户成倍缩短业务上线周期
- 帮助客户成倍降低数据中兴能耗
- 利用虚拟化基础设施的高可用和强恢复能力，实现业务快速自动化故障恢复，降低数据中心成本，增加系统应用的正常运行时间

FusionCompute是FusionSphere虚拟化套件中的必选组件，是云操作系统软件，主要负责硬件资源的虚拟化，以及对虚拟资源、业务资源、用户资源的集中管理。

采用虚拟计算，虚拟存储，虚拟网络等技术，完成计算资源，存储资源，网络资源的虚拟化。

**组成**

- CNA(计算节点代理)
- VRM(虚拟资源管理器)

其他资料有UVP，是华为研发的同一虚拟化平台，与KVM和Xen一样，也是一款Hypervisor。

**CNA**

相当于KVM中QEMU + KVM模块，主要提供虚拟化功能，通常以集群的方式部署，将集群内的计算，存储和网络资源虚拟化成资源池供用户使用。同样，CNA也是基于Linux操作系统。

主要功能

- 提供虚拟计算功能
- 管理计算节点上的虚拟机
- 管理计算节点上的计算、存储、网络资源

**VRM**

相当于KVM中的管理工具，管理员和用户可以通过图形化的Portal对FusionCompute进行管理和使用。是基于Linux操作系统。

主要功能

- 管理集群内的块存储资源
- 管理集群内的网络资源(IP/VLAN)，为虚拟机分配IP地址
- 管理集群内虚拟机的生命周期以及虚拟机在计算节点上的分布和迁移
- 管理集群内资源的动态调整
- 通过对虚拟资源、用户数据的统一管理，对外提供弹性计算、存储、IP等服务
- 通过提供统一的操作维护管理接口，操作维护人员通过WebUI远程访问FusionCompute，对整个系统进行操作维护，包含资源管理、资源监控、资源报表等

区别

​	VRM和CNA都有管理的作用，CNA管理的是本节点上的虚拟机和资源，而VRM是从集群或者整个资源池的层面进行管理。如果VRM对某个虚拟机进行修改或者其他生命周期的操作时，需要将命令下发给CNA节点。再由CNA去执行。操作完成后，CNA再将结果返回给VRM，由VRM记录到数据库中。所以尽量不要到CNA上执行虚拟机或其他资源的修改操作，以避免造成VRM数据库中的记录与实际不匹配的情况。

## 云计算网络基础

### 网络流量

​	在云计算和虚拟化中，数据中心的流量分为南北向流量和东西向流量。一般情况，南北向流量和东西向流量事宜路由器为分界点，物理是物理路由器或者虚拟路由器都适用。

​	经过路由器的流量为南北向流量，不经过路由器的流量为东西向流量。

例：

​	该路由器被部署在IDC机房的边界处，向上连接外网，向下链接IDC机房的业务网络，当外网访问IDC机房业务时，该流量为南北向流量；如果IDC机房内运行了员工的个人虚拟机，该虚拟机访问业务时，不需要经过路由器，同样访问业务的流量，但该流量为东西向流量。

![1577597402(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577597402(1).jpg?raw=true)

### 网络基本概念

**广播和单播**

- 广播：一个人说话，剩余的人听。第一次通信需要使用广播；DHCP使用的是广播；不同业务之间使用不用的广播地址来区分。
- 单播：一个人说，另外一个人听。发送邮件，查看网页以及玩网络游戏都是单播的形式。

**路由和默认网关**

- 路由：广播域之间的通信，需要路由表，通过路由表查找对方的方式
- 默认网关：如果路由表条目很多，每次通信时都需要进行路由的查找，会给保存路由表的设备带来负担，也会影响通信的效率，就会用到默认网关。默认网关在收到通信请求时，如果自己的路由表中存在目的地址的网段，则会替通讯的发起者进行路由的转发，如果自己的路由表没有目的地址，它会给发起者返回一个目的地址不可达的消息。

**VLAN**

​	VLAN是将一个物理的LAN在逻辑上划分为多个广播域的通信技术。同一个VLAN内的主机间可以直接通信，而不同VLAN内的主机间不能直接通信，从而将广播报文限制在一个VLAN内。

 ![1577609343(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577609343(1).png?raw=true)

优点

- 限制广播域：被限制在一个VLAN内，节省带宽，提高网络处理能力。
- 增强局域网的安全性：不同VLAN内的报文在传输时是相互隔离的，即一个VLAN内的用户不能与其他VLAN内的用户直接通信
- 提高网络健壮性：故障被限制在一个VLAN内，本VLAN内的故障不会影响其他VLAN的正常工作。
- 灵活构建虚拟工作组：用VLAN可以将不同的用户划分到不同的工作组，同一工作组的用户也不必局限在某一个固定的物理范围，网络构建和维护会更加灵活。

### 物理网络

​	路由工作在传输层(三层)，VLAN工作在网络层(二层)。如果某台设备具备路由功能，可以查看路由表，我们就把它当成三层设备，如果仅可以划分VLAN，就把它当成二层设备。

​	工作在传输层的设备有路由器和三层交换机，工作在网络层的设备一般是二层交换机，而物理服务器的网卡，连接网卡的网线以及光纤等线路则属于链路层的设备。

**链路集合技术**

​	端口聚合通过将多条以太网物理链路捆绑在一起成为一条逻辑链路，实现增加链路带宽的目的。同时，这些捆绑在一起的链路通过相互间的动态备份，可以有效提高链路的可靠性。

优势

1. 增加带宽：链路聚合接口的最大带宽可以达到各成员接口的带看之和
2. 提高可靠性：当某条活动链路出现故障时，流量可以切换到其他可用的成员链路上，从而提高聚合链路的可靠性。
3. 负载分担：在一个链路聚合组内，可实现个成员活动链路间的负载分担

**LACP**

链路聚合分为手工负载分担模式和LACP模式

1. 手工负载分担模式：链路的创建，成员接口的添加由手工配置，不需要链路聚合控制协议(LACP)的参与。该模式下所有活动链路都参与数据的转发，平均分担流量，称为负载分担模式。如果某条活动链路故障，链路聚合中的剩余活动链路会自动平均分担流量。
2. 因为手工负载分担模式无法检测到链路层故障，链路错连等。LACP模式就是采用LACP的一种链路聚合模式。提供一种标准的协商方式，以供设备根据自身配置自动形成聚合链路并启动聚合链路来收发数据。形成聚合链路后，LACP负责维护链路状态，在聚合条件发生变化时，自动调整或解散链路聚合。

物理网卡

![1576818035(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818035(1).jpg?raw=true)

### 虚拟网络

平时使用的虚拟化大多是这架构，在个人或者小型的虚拟化中，虚拟机会以桥接或NAT的方式与物理网卡绑定，而在企业级的大规模场景下，虚拟机都是通过虚拟交换机连接到物理网络的。

![1576818093(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818093(1).jpg?raw=true)

**桥接和NAT**

网桥：把一台机器上的若干网络接口连接起来，其中一个网口收到报文时会复制给其他网口，这样网口之间能够正常通信了。

在虚拟化中，将所有网口连接到一起的工作由操作系统完成。

 ![1577626464(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577626464(1).jpg?raw=true)

​	网桥设备Bridge0绑定eth0和eth1，对于上层网络协议来说，只能看到Bridge0，因为桥接是在数据链路层实现的，上层不需要关心桥接的具体细节。上层协议栈将需要发送的报文发送给Bridge0，由网桥判断报文该转发给eth0还是eth1，或者两者都转发；

网桥流量转发

 ![1577626756(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577626756(1).jpg?raw=true)

​	每个虚拟机都会有一个虚拟网卡，Linux操作系统会在用户态生成一个TAP设备。同时，在内核态生成一个tun/tap的设备驱动和虚拟网卡驱动。虚拟机发出的数据包经过用户态的tun/tap字符设备文件，然后经过内核态的tun/tap设备驱动和虚拟网卡驱动，发给TCP/IP协议栈，再转发到用户态的虚拟网卡tap，tap此时直接连在网桥Bridge0上。

​	如果仅适用网桥，虚拟机和外部通讯时有两种方式 - 桥接和NAT。

**桥接** ：网桥相当于一个交换机，虚拟网卡连接的是交换机的一个端口；

**NAT** ：网桥相当于一个路由器，虚拟网卡连接的是路由器的一个端口；

![1576818121(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818121(1).jpg?raw=true)

**虚拟交换机**

​	Open vSwitch是一款开源的，高质量的，支持多层协议的虚拟交换机。其目的是使用规模网络自动化可以通过编程扩展，同时仍然支持标准的管理接口和协议(例如NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag)，支持多种Linux虚拟化技术，比如Xen和KVM等。

 Open vSwitch主要组件：

- ovs - vswitchd: OVS的主要模块，实现switch的daemon，包括一个支持流交换的Linux内核模块；
- ovsdb - server: 一款轻量级数据库服务器，提供 ovs - vswitchd获取配置信息；
- ovs - dpctl: 用来配置switch内核模块；
- scripts and specs: 辅助OVS安装在Citrix XenServer上，作为默认switch；
- ovs - vsctl: 用来查询和更新ovs - vswitchd的配置；
- ovs - appctl: 用来发送命令消息，运行相关daemon；

OVS还提供一些工具：

- ovs - ofctl: 查询和控制OpenFlow交换机和控制器；
- ovs - pki: OpenFlow交换机创建和管理公钥框架；


OVS数据包转发流程

- 虚拟机产生的数据包先发送到虚拟网卡eth0中；
- 数据包会首先发送到tun/tap设备上，就是图中的vnet；
- 然后再由vnet发送到网桥上；
- 最后经过网桥设备转发到同样桥接的物理网卡eth1上，并由eth1将该数据包转发到物理的二层交换机上。

 ![1577678319(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577678319(1).jpg?raw=true)

### 华为虚拟化产品网络特性

**网络方案**

华为虚拟机产品使用的虚拟交换机为分布式交换机。通过分布在各物理服务器的虚拟交换机，提供虚拟机的二层通信、隔离、QoS能力。

分布式交换机模型基本特征：

1. 虚拟化管理员可以配置多个分布式交换机，每个分布式交换机可以覆盖集群中的多个CNA节点；
2. 每个分布式交换机具有多个分布式虚拟端口VSP，每个VSP具有各自的属性(速率，统计)，为了管理方便采用端口组Port Group来管理具有相同属性的一组端口，相同端口组的VLAN相同；
3. 虚拟化管理员或业务系统(例如VDI/IDC)可选择管理/存储/业务使用的不同物理接口；
4. 每个VM可以具有多个vNIC接口，vNIC可以与交换机的VSP一一对接；
5. 虚拟化管理员或业务系统可根据业务需求，在一个集群中选择允许进行2层迁移的服务器创建虚拟二层网络，设置该网络使用的VLAN信息；

基本组织

- 端口组：端口组是网络属性相同的一组端口的集合。管理员可以通过配置端口组属性(带宽QOS，2层安全属性，VLAN等)来简化对虚拟机端口属性的设置。
- 上行链路：分布式交换机关联的服务器物理网口，管理员可以查询上行链路的名称，速率，模式，状态等信息。
- 上行链路聚合：分布式交换机关联的服务器绑定网口，绑定网口可以包含多个物理网口，这些物理网口可以配置主备或负载均衡策略。

华为分布式虚拟交换机的架构

 ![1577679447(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577679447(1).jpg?raw=true)

特点

1. 集中的管理：统一的Portal和集中的管理，简化用户的管理和配置；
2. 开源Open vSwitch：集成开源Open vSwitch，充分利用和继承了开源社区虚拟交换的能力；
3. 提供丰富的虚拟交换二层特性，包括交换、QoS、安全隔离等；

**分布式交换机流量走向**

1. 虚拟机运行在相同主机，但是端口组不同

   不再同一端口组，就代表不在同一VLAN，所以无法通过广播找到对方。因此访问流量需要从主机内部转发出物理的接入交换机，转发到三层设备经过路由后再进入到主机内部，才能完成通信。

2. 虚拟机运行在相同主机，且端口组相同

   属于同一端口组，则虚拟机属于同一广播域，而虚拟交换机支持广播。可以直接通过虚拟交换机完成，通信的流量不需要传出到物理网络中。

3. 虚拟机运行在不同主机，但端口组相同

   可以广播找到，但不同物理服务器使用不同交换机接入网络中。流量需要通过物理服务器的网口传出到物理交换机上，然后才能完成通信。两台虚拟机之间可以不经过三层设备即可正常通信。

4. 同一物理服务器运行不同的DVS

   使用不同的DVS，两台DVS上的端口组的VLAN ID不会相同，这意味着虚拟机会使用不同的IP地址，所以与第一种情况类似，虚拟机之间的通信，数据包会先到三层设备进行路由，然后才能正常通信。


**安全组**

​	虚拟机加入安全组后，即受到该访问规则的保护。安全组是一个逻辑上的分组，由同一个地域内具有相同安全保护需求并相互信任的虚拟机组成。位于同一安全组的所有虚拟机网卡都将使用该安全组规则进行网络通信。每块虚拟机网卡只能加入一个安全组中。 

​	安全组的作用于防火墙类似，使用iptables的包过滤来实现安全控制。

![1577712884(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577712884(1).jpg?raw=true)

​	iptables是通过配置表中的链与规则来进行处理的，进入链处理的网络报文会依序匹配链中的规则，匹配某个规则会根据规则中指定的操作进行下一步操作。iptables包含4个表，分别是RAW，Filter(包过滤)，NAT(网络地址转换)，Mangle(TCP头修改)，这些表根据需要在上述5个关键点生成自己的处理链，并将链处理的入口函数挂载在对应的关键点上。

**虚拟交换模式**

华为虚拟交换提供三种虚拟交换模式

1. 普通模式
2. SR - IOV直通模式
3. 用户态交换模式

- 普通模式

  虚拟机有前后端两个虚拟网卡设备，其中前端网卡连接在虚拟交换机的虚拟端口上。虚拟机的网络数据包通过环形缓冲区和事件通道在前后端网卡之间传输，并最终通过后端网卡连接的虚拟交换机实现转发。

- SR - IOV直通

  支持SR - IOV的物理网卡可以虚拟出多个虚拟网卡以供虚拟机使用，对于虚拟机来说就像是使用一块单独的物理网卡一样，相比软件虚拟化提升网络I/O性能，相对于硬件直通(PCI Passthrough)减少硬件网卡数量上的需求。

- 用户态交换

  通过对虚拟端口加载用户态驱动，在vswitch中启动线程接管内核态收发包功能，从网卡收到的数据包直接在vswitchd的线程中接收，接收到数据包后，查询vswitchd中的精确流表匹配，然后执行openflow的动作和指令，把数据从指定端口发送出去。相较于 SR - IOV技术，支持热迁移、热添加网卡等更多高级特性。


FusionCompute网络架构

![1576818197(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818197(1).jpg?raw=true)

## 云计算存储基础

**虚拟化存储架构**

![1576818296(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818296(1).jpg?raw=true)

最底层是物理磁盘，最上层是云硬盘，中间经过一系列逻辑划分，文件系统格式化等操作。

**虚拟化存储转换路径**

 ![1576818338(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818338(1).jpg?raw=true)

**非虚拟化存储转换路径**

 ![1576818380(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818380(1).jpg?raw=true)

### 物理磁盘类型

- SATA：采用串行连接方式，串行ATA总心啊使用嵌入式时钟信息，具备更强的纠错能力。
- SAS：串行连接SCSI，采用串行技术获得更高的传输速度，并通过缩短连接线改善内部空间等。此接口的设计是改善存储系统的效能，可用性和扩充性，并且提供与SATA硬盘的兼容性。
- NL - SAS：采用SAS磁盘接口和SATA盘体的综合体，在寻址和速度上有了提升。
- SSD：用固态电子存储芯片阵列而制成的硬盘，由控制单元和存储单元(FLASH芯片，DRAM芯片)组成。具有快速读写，质量轻，能耗低以及体积小等。

![1577760578(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577760578(1).jpg?raw=true)

### 集中式和分布式存储

**集中式**

所有资源都集中在某一个中心，然后通过统一接口向外提供服务。集中式存储按照技术架构可以分为SAN和NAS，其中SAN可以细分为FC-SAN、IP-SAN、FCoE-SAN。

 ![1576818746(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818746(1).jpg?raw=true)

**SAN存儲**

​	存储区域网络(SAN)是一种独立于业务网络系统之外，以块级数据为其基本访问单位的高速存储专用网络。这种网络的主要实现形式有光纤通道存储区域网络(FC-SAN)、IP存储区域网络(IP-SAN)和SAS粗才能区域网络(SAS-SAN)。不同的实现形式分别采用不同的通信协议和连接方式在服务器和存储设备之间传输数据、命令和状态。

**集中式存储类型**

![1576818850(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818850(1).jpg?raw=true)

### RAID机制

​	RAID，冗余磁盘阵列。已拥有RAID-0 ~ RAID-6共7种基本的RAID级别。另外，还有一些基本RAID级别的组合形式，如RAID-10(RAID-0 和 RAID-1的组合)、RAID-50(RAID-5 和 RAID-0的组合)等。

- RAID-0

  条带化，原理是将多个物理磁盘合并成一个大的逻辑磁盘，代表所有RAID级别中最高的存储性能，不具备冗余，不能并行I/O，但速度最快。

  RAID0有Disk 1和Disk 2两个磁盘，将要存储的内容(D1，D2)根据磁盘数目分成两部部分同时存储。读写性能好，但是没有数据冗余。

- RAID-1

  又称为镜像，其目的是最大限度保证用户数据的可用性和可修复性。RAID-1的原理是把用户写入硬盘的数据百分百地自动复制到另外一块硬盘上。当主硬盘损坏时，镜像硬盘代替主硬盘工作，但磁盘利用率最低。

- RAID-5

  RAID-5是高级RAID系统中最常见的一种RAID级别，由于其出色的性能和数据冗余平衡设计而被广泛采用。全名是"独立的数据磁盘与分布式校验块"。使用奇偶校验来进行校验和纠错。

  例：图中以三个硬盘为例，P为数据的校验值，D为真实的数据。RAID-5不对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID-5的各个磁盘，并且数据和相对应的奇偶校验信息分别存储在不同的磁盘上。当一个磁盘数据发生损坏后，利用剩下的数据和相应的奇偶校验信息可以恢复被损坏的数据。

- RAID-6

  RAID-6是为了进一步加强数据保护而设计的一种RAID方式。与RAID-5相比，增加第二种独特的奇偶校验信息块。，诶个数据块都有两个校验保护：分层校验和总体校验，因此数据冗余性能非常好。

  常见的RAID-6技术有P + Q和DP两种，获取校验信息的方法不同，但是都可以允许整个阵列中两块磁盘数据丢失。

![1576818793(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818793(1).jpg?raw=true)

### 分布式存储和副本机制

​	分布式存储技术通过网络将企业每台机器上的磁盘空间集中起来，并将这些分散的存储资源构成一个虚拟的存储设备，数据分散地存储在企业的各个角落。

 ![1576818876(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818876(1).jpg?raw=true)

**副本机制**

​	副本机制是将数据复制成多份一模一样的内容，并分别保存在不同的服务器上，当某台服务器出现故障后，数据并不会丢失。分布式存储系统把所有服务器的本地硬盘组成若干个资源池，基于资源池提供创建/删除应用卷，创建/删除快照等接口，为上层软件提供卷设备功能。

 ![1576818921(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1576818921(1).jpg?raw=true)

![1577777368(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577777368(1).jpg?raw=true)

分布式存储优势：

- 性能卓越
- 全局负载均衡
- 分布式SSD存储
- 高性能快照
- 高性能链接克隆
- 高速InfiniBand网络

### 虚拟化存储和非虚拟化存储

RAID和LUN

- RAID由几个硬盘组成，从整体上相当于由多个硬盘组成的一个大的物理卷
- 在物理卷的基础上可以按照指定容量创建一个或多个逻辑单元，这些逻辑单元称为LUN，可以作为映射给主机的基本块设备

 ![1577156037(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577156037(1).jpg?raw=true)

​	这里的存储虚拟化是仅指集群是否有文件系统，这里的文件系统可以使NFS，也可以是虚拟化集群的文件系统。如果没有文件系统，虚拟化集群需要直接调用逻辑卷使用。

​	虚拟化程序使用的最小存储单位是LUN，与LUN对应的是卷Volume，卷是存储系统内部的管理对象，LUN是Volume的对外体现。

使用虚拟化后，LUN可以分为Thick LUN和Thin LUN。

- Thick LUN是传统非精简LUN。支持虚拟资源分配，能够以较简便的方式进行创建、扩容和压缩操作。创建完成就会从存储池中分配满额的存储空间，即LUN的大小完全等于分配的空间。因此有较高的、可预测的性能。
- Thin LUN是精简LUN，支持虚拟资源分配，能够以较简便的方式进行创建、扩容和压缩操作。在创建时，可以设置初始分配容量。创建完成后，存储池只会分配初始容量大小的空间，剩余的空间还在存储池中。

主要区别：

1. 空间分配

   Thick LUN在创建时存储池会分配所有需要的存储空间。

   Thin LUN是一种按需分配的空间组织方法，在创建时存储池不会分配所有哦需要的存储空间，而是根据使用情况动态分配。

    ![1577933438(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577933438(1).jpg?raw=true)

2. 空间回收

   释放存储池中的资源，并且这些释放的资源可以被其他LUN重新使用。Thick LUN没有空间回收的概念。Thin LUN不经能随空间占用率的增大，自动分配新的存储空间，而且当Thin LUN中的文件删除时也可以实现存储空间的释放，实现存储空间的反复利用。

    ![1577933607(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577933607(1).jpg?raw=true)

3. 性能区别

   Thick LUN因为一开始就会拥有所有的分配空间，所有Thick LUN在顺序读写时拥有较高的性能。

   Thin LUN因为实时分配空间，每次扩容时，需要重新增加容量，后台重新格式化，性能受到一定的影响。而且每次分配空间后可能导致硬盘中的存储空间不连续，硬盘在读写数据时会在寻找存放位置上花费较多的时间。

4. 使用场景

   Thick LUN 

   1. 对性能要求较高的场景
   2. 对存储空间利用率不太敏感的场景
   3. 对成本要求不太高的场景

   Thin LUN

   1. 对性能要求一般的场景
   2. 对存储空间利用率比较敏感的场景
   3. 对成本要求比较敏感的场景
   4. 在实际应用中很难预估存储空间的场景

除了虚拟化集群文件系统外，常见的文件系统还有NAS存储文件系统(NFS和CIFS)和操作系统文件系统。

 ![1577934073(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577934073(1).jpg?raw=true)

操作系统文件系统的工作过程

![1577934125(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577934125(1).jpg?raw=true)

首先，用户或者应用程序创建文件或文件夹；

第二，这些文件或文件夹会被保存在文件系统上；

第三，文件系统将这些文件对应的数据映射到文件系统块上；

第四，文件系统块与逻辑卷形成的逻辑区域进行对应；

第五，通过操作系统LVM将逻辑区域映射到物理磁盘的物理区域；

最后，物理区域所对应的物理卷可能会包含一块或多块物理磁盘。

### 虚拟机磁盘

​	虚拟机由两部分组成：配置文件和磁盘文件。使用虚拟化存储，所有的磁盘文件都会以文件的形式存放到文件系统形成的共享目录中，如果使用非虚拟化存储，每个磁盘文件对应一个LUN。

常见虚拟机磁盘格式

 ![1577934629(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577934629(1).jpg?raw=true)

### 华为虚拟化存储特性

​	FusionCompute使用的存储资源可以来自本地磁盘或专用的存储设备。数据存储是FusionCompute对粗才能资源中的存储单元进行的统一封装。存储资源封装成数据存储并与主机关联后，能进一步创建成若干虚拟磁盘，供虚拟机使用。

能够封装为数据存储的存储单元包括

- SAN存储上划分的LUN
- NAS存储上划分的文件系统
- FusionStorage Block上的存储池
- 主机的本地硬盘(虚拟化)

这些存储单元在华为FusionCompute中统称为**存储设备**，而向虚拟化提供存储空间的物理存储介质被称为**存储资源**。

**华为虚拟化磁盘特性**

华为虚拟机磁盘可分为以下几种：

- 按照类型，可将虚拟机磁盘分为普通和共享
  - 普通：普通磁盘只能提供给单个虚拟机使用；
  - 共享：共享磁盘可以绑定给多个虚拟机使用；
- 根据配置模式，可将虚拟机磁盘分为普通、精简和普通延迟置零
  - 普通：该模式下，磁盘分配空间即磁盘容量，在创建过程中会将物理设备上保留的数据置零。这种格式的磁盘性能要优于其他两种磁盘格式，但创建需要的时间更长。
  - 精简：系统首次仅分配磁盘容量设置值的一部分，后续根据使用情况，逐步进行分配，直至分配总量达到磁盘容量配置值为止。
  - 普通延迟置零：磁盘容量即为磁盘分配空间，但创建时不会擦除物理设备上保留的任何数据，从而虚拟机首次执行写操作时开始按需将其置零。创建速度比普通模式块；I/O性能介于普通和精简两种模式之间。这种磁盘的配置模式只支持数据存储类型为虚拟化本地硬盘或虚拟化SAN存储。
- 根据磁盘模式，可将虚拟机磁盘分为从属、独立-持久和独立-非持久
  - 从属：快照中包含该磁盘，更改将立即并永久写入磁盘
  - 独立-持久：更改将立即并永久写入磁盘，持久磁盘不受快照影响
  - 独立-非持久：关闭电源或恢复快照后，丢弃对该磁盘的更改

*注：若选择 独立-持久 或 独立-非持久，则对虚拟机创建快照时，不对该磁盘的数据进行快照。使用快照还原虚拟机时，不对该磁盘的数据进行还原。*

## 虚拟化特性介绍

虚拟化特点：分区、隔离、封装、独立

### 虚拟化集群特性

- HA：使用集群技术，克服单台物理主机的局限性，最终达到业务不中断或者中断时间减少的效果。
- 负载均衡
- 易扩容
- 内存复用

**HA**

解决发现主机故障问题

CNA主机和VRM通过心跳机制来保证VRM有效感知CNA节点是否发生异常，具体如下：

- CNA主机侧有某个进程或服务承载心跳机制的任务；
- 主机每隔3s向VRM主动上报心跳，如果连续10次，即30s没有上报心跳，则会置此主机为故障状态；
- 主机每次上报心跳都有超时机制，socket连接，接收，发送超时时间均为10s；
- VRM侧每收到一个主机侧发来的心跳就将心跳频率设置为10；线程没3s会将该值减1，如果小于等于0，则认为此值对应的主机结点异常。

虚拟机不能正常启动问题

虚拟机在其他主机上启动，可能业务无法自启动，甚至操作系统无法正常启动。HA中的业务会借助浮动IP，Keeplived等与高可用相关的技术，将业务在备用的虚拟机上恢复。

防止脑裂

脑裂是由于共享存储可能会同时被两个虚拟机执行写操作而造成。系统在进行启动虚拟机前会检测对应的存储是否有写操作，如果有，则证明主机有可能没有出现故障，这时候，系统就不会在继续执行虚拟机的启动操作了，而是直接在管理系统的页面显示HA成功。

**负载均衡**

将特定的业务(网络服务，网络流量等)分担给多台网络设备(包括服务器，防火墙等)或多条链路，从而提高业务处理能力。

优势

- 高性能
- 可扩展性
- 高可靠性
- 可管理性
- 透明性

负载的阈值可以由系统管理员指定，也可以使用系统自定义。比如CPU和内存的使用率超过60%时，VRM就会将此CNA主机上的虚拟机迁移到其他节点上。

**内存复用**

内存复用技术主要包括：内存气泡、内存置换、内存共享。

- 内存共享：多台虚拟机共享数据内容相同的内存页。Hypervisor在做内存映射时，会同时将这段内存映射给不同的虚拟机，为了保证这段内存的数据不会被任意虚拟机修改，所有的虚拟机对该内存只有读操作权限。
- 内存气泡：系统主动回收虚拟机暂时不用的物理内存，分配给需要复用内存的虚拟机。内存的回收和分配为系统动态执行，虚拟机上的应用无感知。整个物理服务器上的所有虚拟机使用的分配内存总量不能超过该服务器的物理内存总量。
- 内存置换：将外部存储虚拟成内存给虚拟机使用，将虚拟机上暂时不用的数据存放到外部存储上。系统需要使用这些数据时，再与预留在内存上的数据进行交换。

 ![1577156368(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577156368(1).jpg?raw=true)

### 虚拟机部署

虚拟机快速部署通过两种方式实现：按模板部署和虚拟机克隆。

虚拟机资源热添加CPU和内存，存储和网络资源。

各个虚拟机厂商都为虚拟机配置Console管理的功能。使用Console不代表不依赖网络，登录虚拟机时，虚拟机可以不配置IP地址，但是虚拟机所在的计算节点需要配置IP地址，并且该计算节点会作为服务端，为用户登录虚拟机提供服务。

虚拟机快照一般应用在当对虚拟机进行升级、打补丁、测试等破坏性试验前。虚拟机出现故障，使用快照恢复。常见的快照模式分为：写前拷贝(COW)和写时重定向(ROW)快照。

![1577156466(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577156466(1).jpg?raw=true)

### DRS规则

DRS是负载均衡的一部分，通过一定的规则，为系统在进行负载均衡提供迁移参考

- 聚集虚拟机：列出的虚拟机必须在同一主机上运行，一个虚拟机只能被加入一条聚集虚拟机规则中。
- 互斥虚拟机：列出的虚拟机必须在不同主机上运行，一个虚拟机只能被加入一条互斥虚拟机规则中。
- 虚拟机到主机：关联一个虚拟机组和主机组并设置关联规则，指定所选的虚拟机组的成员是否能够在特定主机组的成员上运行。

如果不同的规则发生冲突，规则的调度优先级如下：

- 第一优先级：规则类型为"虚拟机到主机"，规则是"必须在主机组上运行"和"禁止在主机组上运行"的。
- 第二优先级：规则类型为"聚集虚拟机"和"互斥虚拟机"的。
- 第三优先级：规则类型为"虚拟机到主机"，规则是"应该在主机组上运行"和"不应该在主机组上运行"的。

### IMC

设置集群的IMC策略，使虚拟机可以在不同CPU类型的主机之间进行迁移。

*注：IMC策略仅支持Intel不同型号CPU的热迁移*

设置集群IMC策略时，如果集群中有主机或虚拟机，必须满足条件：

- 集群下主机的CPU功能集必须等于或高于设置的目标基准功能集。
- 集群运行或休眠状态的虚拟机CPU功能集必须等于或低于目标基准功能集。

### QOS

**CPU QOS**

包含三个参数

- CPU资源份额
- CPU资源预留
- CPU资源限额

内存 QOS

通过内存气泡等内存复用技术将物理内存虚拟出更多的虚拟内存，参数包括

- 内存资源份额
- 内存资源预留
- 内存资源限额

**网络 QOS**

提供带宽配置控制能力，QOS功能不支持同一主机上虚拟机之间的流量限制。包含：

- 基于端口组成员接口发送方向和接收方向的带宽控制
- 基于端口组的每个成员接口提供流量整形、带宽优先级的控制能力

## 云计算发展

OpenStack组成

![1577156697(1)](https://github.com/orangehaswing/HCIA-CloudComputing/blob/master/resources/1577156697(1).jpg?raw=true)

















































